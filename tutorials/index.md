

These tutorials introduce fundamental concepts in deep learning
and their realizations in _MXNet_.
Each tutorial builds upon the previous ones.
For example, our tutorial on linear regression
introduces fundamental ideas in supervised learning,
and the basic machinery for handling data and training models in _MXNet_.
In contrast, our tutorial on multilayer perceptrons
introduces hidden representations, activation functions, and dropout regularization.
Finally, our tutorials on _convolutional neural networks_ (CNNs)
and _recurrent neural networks_ (RNNs),
focus on working with image data and sequential data respectively.

Each tutorial contains a high-quality working examples,
accessible both as Jupyter notebooks and as clean code examples.
Feel free to grab these implementations as starting points
for building your own projects with _MXNet_.
