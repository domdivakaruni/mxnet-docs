

These tutorials introduce fundamental concepts in deep learning
and their realizations in _MXNet_.
Each tutorial builds upon the previous ones.
For example, our tutorial on linear regression
introduces fundamental ideas in supervised learning,
and the basic machinery for handling data and training models in _MXNet_.
In contrast, our tutorial on multilayer perceptrons
introduces hidden representations, activation functions, and dropout regularization.
Finally, our tutorials on _convolutional neural networks_ (CNNs)
and _recurrent neural networks_ (RNNs),
focus on working with image data and sequential data respectively.

Each tutorial contains a high-quality working examples,
accessible both as Jupyter notebooks and as clean code examples.
Feel free to grab these implementations as starting points
for building your own projects with _MXNet_.

## Basic
* [Linear Regression - House Prices](http://mxnet.io)
* [Logistic Regression - Handwritten Digits](http://mxnet.io)
* [Multilayer Perceptron - Handwritten Digits](http://mxnet.io)
* [Convolutional Neural Networks (Simple) - Handwritten Digits](http://mxnet.io)
* [Convolutional Neural Networks (Advanced) - House Numbers](http://mxnet.io)
* [Recurrent Neural Networks - Character-level Language Modeling](http://mxnet.io)

## Advanced
* [Sequence to Sequence RNNs - English to French Translation](http://mxnet.io)
* [Generative Adversarial Networks - Synthesizing Pictures of Faces](http://mxnet.io)
* [Deep Q-Learning (DQN) - Playing Atari with Deep Learning](http://mxnet.io)
